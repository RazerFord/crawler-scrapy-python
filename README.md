# crawler-scrapy-python
Python crawler using the scrapy library

# Start project
`scrapy startproject bestsellers`

# Start shell
`scrapy shell`

# Netology courses
`https://netology.ru/backend/api/programs`

# Css selector
Click right mouse, choouse css selector

# [Parse dinamic pages](https://docs.scrapy.org/en/latest/topics/dynamic-content.html)

# Start spider and save in csv
`scrapy runspider ./netology/netology/spiders/programs.py -o prog.csv`

# Start spider
`scrapy crawl programs`

# For extract first
`extract_first()` in selectors

# Идеи
Добавить еще одного паука, чтобы он собирал информацию с каждой странички сайта